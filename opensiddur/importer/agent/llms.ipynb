{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8557fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from pathlib import Path\n",
    "BASE_PATH = Path(\".\").absolute().parent.parent.parent\n",
    "\n",
    "sys.path.append(str(BASE_PATH))\n",
    "\n",
    "DATA_PATH = BASE_PATH / \"sources\" / \"1917jps-wikisource\"\n",
    "TEXT_PATH = DATA_PATH / \"text\"\n",
    "CREDITS_PATH = DATA_PATH / \"credits\"\n",
    "\n",
    "with open(BASE_PATH / \"opensiddur\" / \"private\" / \"api_key.txt\", \"r\") as f:\n",
    "    API_KEY = f.read().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbcbe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\".\").absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f47781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import time\n",
    "from typing import Annotated, Literal, TypedDict, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langgraph.graph import END, add_messages\n",
    "from openai import APITimeoutError\n",
    "\n",
    "\n",
    "class Page(BaseModel):\n",
    "    number: int = Field(description = \"Page sequence number\")\n",
    "    content: str = Field(description = \"Page content\")\n",
    "\n",
    "def get_page(page_number: str | int) -> Optional[Page]:\n",
    "    \"\"\" Return the wikitext of the given Page, or None if it does not exist \"\"\"\n",
    "    page_num = int(page_number)\n",
    "    page_file_name = f\"{page_num:04d}.txt\"\n",
    "    try:\n",
    "        with open(TEXT_PATH / page_file_name, \"r\") as f:\n",
    "            return Page.model_validate(dict(number=page_num, content=f.read()))\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "\n",
    "\n",
    "class OutlineItem(BaseModel):\n",
    "    section_title: str = Field(description=\"Title of the section\")\n",
    "    start_page: int = Field(description=\"Page number of the first page of the section\")\n",
    "    \n",
    "# Go through the items in the outline in a sliding window. If 2 items have the same title, remove the first one.\n",
    "def reduce_outline_items(\n",
    "    old: list[OutlineItem],\n",
    "    new: list[OutlineItem]) -> list[OutlineItem]:\n",
    "    combined = sorted(old + new, key=lambda x: x.start_page)\n",
    "    pruned = []\n",
    "    \n",
    "    for i, item in enumerate(combined):\n",
    "        next_item = combined[i+1] if i < len(combined) - 1 else None\n",
    "        if next_item is not None:\n",
    "            if item.section_title == next_item.section_title:\n",
    "                continue\n",
    "        pruned.append(item)\n",
    "    return pruned\n",
    "\n",
    "class Outline(BaseModel):\n",
    "    outline: list[OutlineItem] = Field(description=\"Outline of the book\")\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    current_page: Page = Field(description=\"Page currently being processed.\")\n",
    "   \n",
    "    outline: Annotated[list[OutlineItem], reduce_outline_items] = Field(description=\"Outline of the book\")\n",
    "\n",
    "    next_tool: Literal[\"outline\", \"turn_page\", \"done\"] = Field(description=\"The next tool to call\")\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "\n",
    "def turn_page_forward(state: AgentState) -> AgentState:\n",
    "    \"\"\" Turn the page forward \"\"\"\n",
    "    current_page_number = state[\"current_page\"].number\n",
    "    new_page_number = current_page_number + 1\n",
    "    page_text = get_page(new_page_number) or \"\"\n",
    "    return dict(\n",
    "        current_page = page_text,\n",
    "        next_tool = \"outline\" if page_text else \"done\"\n",
    "    )\n",
    "\n",
    "def printable_state(state: AgentState) -> dict:\n",
    "    outline = \"\"\n",
    "    for item in state[\"outline\"]:\n",
    "        outline += f\"* {item.section_title} ({item.start_page})\\n\"\n",
    "\n",
    "    return {\n",
    "        \"outline\": outline,\n",
    "        \"current_page_number\": state[\"current_page\"].number,\n",
    "        \"current_page\": state[\"current_page\"].content,\n",
    "    }\n",
    "\n",
    "outline_tools = [turn_page_forward]\n",
    "\n",
    "from langchain_openai.chat_models.base import ChatOpenAI\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "class OutlineResponse(BaseModel):\n",
    "    outline: list[OutlineItem] = Field(description=\"Next outline items\")\n",
    "    \n",
    "def outline(state: AgentState) -> AgentState:\n",
    "    print(\"Reading page\", state[\"current_page\"].number)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"\n",
    "# Your role        \n",
    "You are a superlative expert in understanding MediaWiki markup and you are expert in reading and understanding Jewish scripture and liturgical texts.\n",
    "You will be given the content of pages from a book that was encoded into Wikisource as MediaWiki markup.\n",
    "You will direct the generation of an outline of a book.\n",
    "Each item in the outline is a major section of the book.\n",
    "\n",
    "The outline has the following components:\n",
    "# Outline components\n",
    "Title page\n",
    "Table of contents\n",
    "Torah (The Law)\n",
    "  Genesis\n",
    "  Exodus\n",
    "  Leviticus\n",
    "  Numbers\n",
    "  Deuteronomy\n",
    "Nevi'im (The Prophets)\n",
    "  Joshua\n",
    "  Judges\n",
    "  1 Samuel\n",
    "  2 Samuel\n",
    "  1 Kings\n",
    "  2 Kings\n",
    "  Isaiah\n",
    "  Jeremiah\n",
    "  Ezekiel\n",
    "  The Twelve Minor Prophets\n",
    "    Hosea\n",
    "    Joel\n",
    "    Amos\n",
    "    Obadiah\n",
    "    Jonah\n",
    "    Micah\n",
    "    Nahum\n",
    "    Habakkuk\n",
    "    Zephaniah\n",
    "    Haggai\n",
    "    Zechariah\n",
    "    Malachi\n",
    "Ketuvim (The Writings)\n",
    "  Psalms\n",
    "  Proverbs\n",
    "  Job  \n",
    "  Song of Songs\n",
    "  Ruth\n",
    "  Lamentations\n",
    "  Ecclesiastes\n",
    "  Esther\n",
    "  Daniel\n",
    "  Ezra\n",
    "  Nehemiah\n",
    "  Chronicles\n",
    "  Ezra\n",
    "  Nehemiah\n",
    "  1 Chronicles\n",
    "  2 Chronicles\n",
    "\n",
    "# Instructions\n",
    "I will provide you with the current page in MediaWiki markup.\n",
    "The page numbers will be provided for you in the headings above the page content. Do not make up your own page numbers.\n",
    "When a new major section begins, you will return the section title, and the start page of the section in the outline.\n",
    "If the last recorded outline item continues on this page, return the outline as an empty list (outline=[]).\n",
    "\"\"\"),\n",
    "        (\"user\", \"\"\"\n",
    "# Current MediaWiki page = page number {current_page_number}:\n",
    "{current_page}\n",
    "\n",
    "# Outline so far:\n",
    "{outline}\n",
    "        \"\"\")\n",
    "    ]).partial(**printable_state(state))\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"Qwen/Qwen3-235B-A22B-Instruct-2507\", #\"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\", # \"google/gemma-3-27b-it\",\n",
    "        api_key=API_KEY,\n",
    "        base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    "        temperature=0.0,\n",
    "        timeout=10\n",
    "    )\n",
    "    llm = llm.with_structured_output(OutlineResponse)\n",
    "    llm = prompt | llm\n",
    "    retry = 0\n",
    "    max_retries = 5\n",
    "    success = False\n",
    "    while not success and retry < max_retries:\n",
    "        try:\n",
    "            response = llm.invoke({\"user\": \"Go.\"})\n",
    "            success = True\n",
    "        except APITimeoutError as e:\n",
    "            print(f\"Timeout error, retrying {retry+1}/{max_retries}...\")\n",
    "            time.sleep(1.0)\n",
    "            retry += 1\n",
    "            if retry >= max_retries:\n",
    "                raise e\n",
    "        except Exception as e:\n",
    "            raise\n",
    "    if response.outline:\n",
    "        print(response)\n",
    "    return {\n",
    "        \"outline\": response.outline,\n",
    "        \"next_tool\": \"turn_page\"\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "def conditional_edge(state: AgentState) -> str:\n",
    "    return state[\"next_tool\"]\n",
    "\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"outline\", outline)\n",
    "workflow.add_node(\"turn_page\", turn_page_forward)\n",
    "workflow.add_conditional_edges(\n",
    "    \"turn_page\",\n",
    "    conditional_edge,\n",
    "    {\n",
    "        \"outline\": \"outline\",\n",
    "        \"done\": END\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"outline\", \"turn_page\")\n",
    "workflow.set_entry_point(\"outline\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf6f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Image\n",
    "from IPython.display import display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5911e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = app.invoke({\"current_page\": get_page(7), \n",
    "\"outline\": []}, config={\"recursion_limit\": 5000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e767d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outline = response[\"outline\"]\n",
    "for item in outline:\n",
    "    print(item.section_title, item.start_page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395b4753",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_page(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eed767c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fielda': 3, 'fieldb': 'b', 'fieldc': {'one': 'two'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class TestBaseModel(BaseModel):\n",
    "    fielda: int = Field(description=\"A field\")\n",
    "    fieldb: str = Field(description=\"Another field\")\n",
    "    fieldc: dict = Field(description=\"A dictionary field\", default_factory=dict)\n",
    "\n",
    "test_model = TestBaseModel(fielda=1, fieldb=\"b\")\n",
    "\n",
    "test_model.fieldc[\"one\"] = \"two\"\n",
    "\n",
    "test_model.fielda = 3\n",
    "\n",
    "test_model.model_dump()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "285d7e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efeins/.cache/pypoetry/virtualenvs/opensiddur-ai-k0CrJpLF-py3.13/lib/python3.13/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `list[str]` - serialized value may not be as expected [input_value=2, input_type=int])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'xml_cache': <opensiddur.exporter.cache.XMLCache at 0x791f968be510>,\n",
       " 'settings': [],\n",
       " 'project_priority': [],\n",
       " 'instruction_priority': [],\n",
       " 'annotation_projects': 2,\n",
       " 'processing_context': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from opensiddur.exporter.linear import get_linear_data\n",
    "\n",
    "\n",
    "ld = get_linear_data()\n",
    "ld.annotation_projects = 2 #[\"jps1917\", \"wlc\"]\n",
    "ld.model_dump()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensiddur-ai-k0CrJpLF-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
